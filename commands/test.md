---
argument-hint: [pattern | watch | coverage | failed | file.js] (optional: run specific tests or modes)
description: Smart test execution with pattern matching, watch mode, coverage, and failure retry
---

# Test Command

## Purpose
Intelligently run tests based on context - run all tests, specific test files, only changed files, previously failed tests, or tests in watch mode with coverage reporting.

## Command Syntax
- `/test` - Run all tests (or smart selection based on recent changes)
- `/test [pattern]` - Run tests matching pattern (e.g., "auth", "user.test")
- `/test watch` - Run tests in watch mode
- `/test coverage` - Run tests with coverage report
- `/test failed` - Re-run only previously failed tests
- `/test changed` - Run only tests for changed files
- `/test [file]` - Run specific test file
- `/test unit` - Run only unit tests
- `/test integration` - Run only integration tests
- `/test e2e` - Run only end-to-end tests

## User Instructions Processing

**Arguments received:** `$ARGUMENTS`

Parse `$ARGUMENTS` for test targets:
- No args: Run default test suite or smart selection
- Pattern matching: Use grep pattern to filter tests
- Special keywords: `watch`, `coverage`, `failed`, `changed`
- Test types: `unit`, `integration`, `e2e`
- File paths: Run specific test files

## Command Instructions

### 1. Detect Test Framework and Configuration

```bash
# Node.js/JavaScript projects
if [ -f "package.json" ]; then
  # Detect test framework
  if grep -q "\"jest\"" package.json; then
    TEST_FRAMEWORK="jest"
  elif grep -q "\"mocha\"" package.json; then
    TEST_FRAMEWORK="mocha"
  elif grep -q "\"vitest\"" package.json; then
    TEST_FRAMEWORK="vitest"
  elif grep -q "\"cypress\"" package.json; then
    HAS_CYPRESS=true
  elif grep -q "\"playwright\"" package.json; then
    HAS_PLAYWRIGHT=true
  fi

  # Check for test scripts
  grep -q "\"test\"" package.json && HAS_TEST_SCRIPT=true
  grep -q "\"test:watch\"" package.json && HAS_WATCH_SCRIPT=true
  grep -q "\"test:coverage\"" package.json && HAS_COVERAGE_SCRIPT=true
  grep -q "\"test:unit\"" package.json && HAS_UNIT_SCRIPT=true
  grep -q "\"test:integration\"" package.json && HAS_INTEGRATION_SCRIPT=true
  grep -q "\"test:e2e\"" package.json && HAS_E2E_SCRIPT=true
fi

# Python projects
if [ -f "pytest.ini" ] || [ -f "setup.cfg" ] || [ -f "pyproject.toml" ]; then
  TEST_FRAMEWORK="pytest"
elif [ -f "manage.py" ] && grep -q "test" manage.py; then
  TEST_FRAMEWORK="django"
fi

# Other languages
[ -f "Cargo.toml" ] && TEST_FRAMEWORK="cargo"
[ -f "go.mod" ] && TEST_FRAMEWORK="go"
[ -f "pom.xml" ] && TEST_FRAMEWORK="maven"
[ -f "build.gradle" ] && TEST_FRAMEWORK="gradle"
```

### 2. Smart Test Selection

```bash
# Get recently changed files for smart test selection
get_changed_files() {
  # Files changed but not committed
  git diff --name-only 2>/dev/null

  # Files changed in last commit
  git diff --name-only HEAD~1 2>/dev/null
}

# Find related test files for changed source files
find_related_tests() {
  changed_files=$(get_changed_files)
  for file in $changed_files; do
    # JavaScript/TypeScript patterns
    if [[ $file =~ \.(js|jsx|ts|tsx)$ ]]; then
      # Convert source file to test file patterns
      test_file="${file%.*}.test.*"
      spec_file="${file%.*}.spec.*"
      test_dir="$(dirname "$file")/__tests__/$(basename "$file")"

      # Check if test files exist
      [ -f "$test_file" ] && echo "$test_file"
      [ -f "$spec_file" ] && echo "$spec_file"
      [ -f "$test_dir" ] && echo "$test_dir"
    fi

    # Python patterns
    if [[ $file =~ \.py$ ]]; then
      test_file="test_$(basename "$file")"
      test_dir="tests/$(basename "$file")"

      [ -f "$test_file" ] && echo "$test_file"
      [ -f "$test_dir" ] && echo "$test_dir"
    fi
  done
}
```

### 3. JavaScript/TypeScript Test Execution

```bash
# Jest
if [ "$TEST_FRAMEWORK" = "jest" ]; then
  case "$ARGUMENTS" in
    "watch")
      echo "ğŸ‘ï¸  Running Jest in watch mode..."
      npx jest --watch
      ;;
    "coverage")
      echo "ğŸ“Š Running Jest with coverage..."
      npx jest --coverage --colors
      ;;
    "failed")
      echo "ğŸ”´ Re-running failed tests..."
      npx jest --onlyFailures
      ;;
    "changed")
      echo "ğŸ“ Running tests for changed files..."
      npx jest --onlyChanged
      ;;
    "unit")
      echo "ğŸ§ª Running unit tests..."
      npx jest --testPathPattern="unit|spec" --testPathIgnorePatterns="integration|e2e"
      ;;
    "integration")
      echo "ğŸ”— Running integration tests..."
      npx jest --testPathPattern="integration"
      ;;
    "e2e")
      echo "ğŸŒ Running e2e tests..."
      npx jest --testPathPattern="e2e"
      ;;
    "")
      echo "âœ… Running all tests..."
      npx jest --colors
      ;;
    *)
      echo "ğŸ” Running tests matching '$ARGUMENTS'..."
      npx jest --testNamePattern="$ARGUMENTS" --colors
      ;;
  esac
fi

# Vitest
if [ "$TEST_FRAMEWORK" = "vitest" ]; then
  case "$ARGUMENTS" in
    "watch")
      echo "ğŸ‘ï¸  Running Vitest in watch mode..."
      npx vitest watch
      ;;
    "coverage")
      echo "ğŸ“Š Running Vitest with coverage..."
      npx vitest run --coverage
      ;;
    "changed")
      echo "ğŸ“ Running tests for changed files..."
      npx vitest run --changed
      ;;
    *)
      echo "âœ… Running tests..."
      npx vitest run $ARGUMENTS
      ;;
  esac
fi

# Mocha
if [ "$TEST_FRAMEWORK" = "mocha" ]; then
  case "$ARGUMENTS" in
    "watch")
      echo "ğŸ‘ï¸  Running Mocha in watch mode..."
      npx mocha --watch
      ;;
    "coverage")
      echo "ğŸ“Š Running Mocha with coverage..."
      npx nyc mocha
      ;;
    *)
      echo "âœ… Running tests..."
      npx mocha $ARGUMENTS
      ;;
  esac
fi

# Use npm scripts if available
if [ "$HAS_TEST_SCRIPT" = true ]; then
  case "$ARGUMENTS" in
    "watch")
      [ "$HAS_WATCH_SCRIPT" = true ] && npm run test:watch || npm test -- --watch
      ;;
    "coverage")
      [ "$HAS_COVERAGE_SCRIPT" = true ] && npm run test:coverage || npm test -- --coverage
      ;;
    "unit")
      [ "$HAS_UNIT_SCRIPT" = true ] && npm run test:unit || npm test -- --testPathPattern="unit"
      ;;
    "integration")
      [ "$HAS_INTEGRATION_SCRIPT" = true ] && npm run test:integration || npm test
      ;;
    "e2e")
      [ "$HAS_E2E_SCRIPT" = true ] && npm run test:e2e || npm test
      ;;
    *)
      npm test $ARGUMENTS
      ;;
  esac
fi
```

### 4. Python Test Execution

```bash
# Pytest
if [ "$TEST_FRAMEWORK" = "pytest" ]; then
  case "$ARGUMENTS" in
    "watch")
      echo "ğŸ‘ï¸  Running pytest in watch mode..."
      pytest-watch
      ;;
    "coverage")
      echo "ğŸ“Š Running pytest with coverage..."
      pytest --cov=. --cov-report=term-missing --cov-report=html
      ;;
    "failed")
      echo "ğŸ”´ Re-running failed tests..."
      pytest --lf
      ;;
    "changed")
      echo "ğŸ“ Running tests for changed files..."
      pytest --picked
      ;;
    "unit")
      echo "ğŸ§ª Running unit tests..."
      pytest tests/unit -v
      ;;
    "integration")
      echo "ğŸ”— Running integration tests..."
      pytest tests/integration -v
      ;;
    "")
      echo "âœ… Running all tests..."
      pytest -v --color=yes
      ;;
    *)
      echo "ğŸ” Running tests matching '$ARGUMENTS'..."
      pytest -k "$ARGUMENTS" -v --color=yes
      ;;
  esac
fi

# Django
if [ "$TEST_FRAMEWORK" = "django" ]; then
  case "$ARGUMENTS" in
    "coverage")
      echo "ğŸ“Š Running Django tests with coverage..."
      coverage run --source='.' manage.py test
      coverage report
      ;;
    *)
      echo "âœ… Running Django tests..."
      python manage.py test $ARGUMENTS
      ;;
  esac
fi
```

### 5. Other Languages

```bash
# Rust
if [ "$TEST_FRAMEWORK" = "cargo" ]; then
  case "$ARGUMENTS" in
    "watch")
      echo "ğŸ‘ï¸  Running cargo tests in watch mode..."
      cargo watch -x test
      ;;
    "coverage")
      echo "ğŸ“Š Running tests with coverage..."
      cargo tarpaulin
      ;;
    *)
      echo "âœ… Running cargo tests..."
      cargo test $ARGUMENTS
      ;;
  esac
fi

# Go
if [ "$TEST_FRAMEWORK" = "go" ]; then
  case "$ARGUMENTS" in
    "coverage")
      echo "ğŸ“Š Running Go tests with coverage..."
      go test -cover ./...
      ;;
    "watch")
      echo "ğŸ‘ï¸  Running Go tests in watch mode..."
      gotestsum --watch
      ;;
    *)
      echo "âœ… Running Go tests..."
      go test ./... $ARGUMENTS
      ;;
  esac
fi

# Java (Maven)
if [ "$TEST_FRAMEWORK" = "maven" ]; then
  echo "âœ… Running Maven tests..."
  mvn test $ARGUMENTS
fi

# Java (Gradle)
if [ "$TEST_FRAMEWORK" = "gradle" ]; then
  echo "âœ… Running Gradle tests..."
  ./gradlew test $ARGUMENTS
fi
```

### 6. Test Output Processing

```bash
# Parse and format test results
format_test_results() {
  # Capture test output
  output=$1

  # Extract key metrics
  if echo "$output" | grep -q "passed"; then
    passed=$(echo "$output" | grep -oE "[0-9]+ passed" | head -1)
    failed=$(echo "$output" | grep -oE "[0-9]+ failed" | head -1)
    skipped=$(echo "$output" | grep -oE "[0-9]+ skipped" | head -1)

    echo "
TEST RESULTS
============
âœ… Passed: $passed
âŒ Failed: $failed
â­ï¸  Skipped: $skipped
"
  fi

  # Show coverage if available
  if echo "$output" | grep -q "Coverage"; then
    coverage=$(echo "$output" | grep -oE "[0-9]+(\.[0-9]+)?%" | head -1)
    echo "ğŸ“Š Coverage: $coverage"
  fi
}

# Save failed tests for retry
save_failed_tests() {
  echo "$1" > .test-failures
}

# Load previously failed tests
load_failed_tests() {
  [ -f .test-failures ] && cat .test-failures
}
```

## Test Report Format

```
TEST EXECUTION REPORT
====================

ğŸ§ª Test Framework: Jest
ğŸ“ Test Files: 23
â±ï¸  Duration: 4.2s

Results:
  âœ… Passed: 142/150
  âŒ Failed: 3
  â­ï¸  Skipped: 5

Failed Tests:
  âŒ UserAuth â€º should handle invalid tokens
  âŒ API â€º should retry on network error
  âŒ Database â€º should rollback on failure

Coverage:
  ğŸ“Š Overall: 78.4%
  ğŸ“ Statements: 456/582
  ğŸŒ¿ Branches: 123/157
  ğŸ”§ Functions: 89/102

ğŸ’¡ Tips:
  - Run '/test failed' to retry failed tests
  - Run '/test coverage' for detailed coverage report
  - Run '/test watch' for continuous testing
```

## Performance Optimization

- Run tests in parallel when possible
- Use test caching for unchanged files
- Skip setup/teardown for unchanged fixtures
- Prioritize recently changed/failed tests
- Use minimal reporter in CI environments

## Error Handling

```bash
# Handle missing test framework
if [ -z "$TEST_FRAMEWORK" ]; then
  echo "âŒ No test framework detected"
  echo "ğŸ’¡ Try installing a test framework:"
  echo "  npm install --save-dev jest    # for JavaScript"
  echo "  pip install pytest             # for Python"
  exit 1
fi

# Handle test failures gracefully
run_tests() {
  # Run tests and capture exit code
  $1
  exit_code=$?

  if [ $exit_code -ne 0 ]; then
    echo "
âŒ Tests failed with exit code $exit_code
ğŸ’¡ Run '/test failed' to retry failed tests
ğŸ“‹ Run '/fix' to auto-fix common issues
"
  fi

  return $exit_code
}
```

## Usage Examples

**User says:** "/test"
**Result:** Runs all tests or smart selection based on changes

**User says:** "/test auth"
**Result:** Runs tests matching "auth" pattern

**User says:** "/test watch"
**Result:** Starts test runner in watch mode

**User says:** "/test coverage"
**Result:** Runs tests with coverage report

**User says:** "/test failed"
**Result:** Re-runs only previously failed tests

**User says:** "/test src/user.test.js"
**Result:** Runs specific test file

---

This command streamlines test execution with intelligent defaults and powerful options for different testing scenarios.